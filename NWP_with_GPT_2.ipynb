{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class GPT2:\n",
        "    def __init__(self):\n",
        "        super(GPT2, self).__init__()\n",
        "\n",
        "        self.model_type = \"GPT2\"\n",
        "\n",
        "        # Load pre-trained model tokenizer (vocabulary)\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "        # Load pre-trained model (weights)\n",
        "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    def predict_next(self, text, k):\n",
        "        # Encode a text inputs\n",
        "        indexed_tokens = self.tokenizer.encode(text)\n",
        "\n",
        "        # Convert indexed tokens in a PyTorch tensor\n",
        "        tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "        # Set the model in evaluation mode to deactivate the DropOut modules\n",
        "        self.model.eval()\n",
        "\n",
        "        # If you have a GPU, put everything on cuda\n",
        "        tokens_tensor = tokens_tensor.to(device)\n",
        "        self.model.to(device)\n",
        "\n",
        "        # Predict all tokens\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(tokens_tensor)\n",
        "            predictions = outputs[0]\n",
        "\n",
        "        # Get the predicted next sub-word\n",
        "        probs = predictions[0, -1, :]\n",
        "        top_next = [self.tokenizer.decode(i.item()).strip() for i in probs.topk(k)[1]]\n",
        "\n",
        "        return top_next"
      ],
      "metadata": {
        "id": "AFqprlyYxqlo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from next_word_prediction import GPT2\n",
        "\n",
        "\n",
        "def run():\n",
        "    gpt2 = GPT2()\n",
        "\n",
        "    print(\"Input a sentence...\")\n",
        "    while True:\n",
        "        try:\n",
        "            text = input(\"> \")\n",
        "            # Encode a text input\n",
        "            prediction = gpt2.predict_next(text, 5)\n",
        "\n",
        "            print(\"{} {}\".format(text, prediction))\n",
        "\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXRrWwgyz4Yy",
        "outputId": "53678ba9-4d5c-4f04-e82e-acd3d98bd758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input a sentence...\n",
            "> My name is\n",
            "My name is ['John', 'James', 'David', 'Michael', 'a']\n",
            "> you are good\n",
            "you are good ['at', 'to', 'enough', '.', ',']\n",
            "> It's a greate\n",
            "It's a greate [',', '-', '.', 'that', 'y']\n",
            "> It's a nice\n",
            "It's a nice ['way', 'little', 'touch', ',', 'thing']\n",
            "> My father is a\n",
            "My father is a ['doctor', 'very', 'big', 'lawyer', 'great']\n",
            "> You should stay away \n",
            "You should stay away  ['from', '.', 'if', ',', 'and']\n",
            "> I love your\n",
            "I love your ['work', 'blog', 'company', 'art', 'game']\n",
            "> You should take\n",
            "You should take ['a', 'the', 'your', 'care', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QdR3iYbT1L5_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}